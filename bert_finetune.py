# -*- coding: utf-8 -*-
"""BERT_finetune.ipynb

Automatically generated by Colab.

referrence: https://qiita.com/sfjwr/items/6768a942e3f4e6f5f627
"""

"""必要なライブラリのインポート"""

!pip install sentencepiece
!pip install datasets
!pip install transformers

"""評価用の関数を定義"""

import numpy as np
from sklearn.metrics import accuracy_score, precision_recall_fscore_support

def compute_metrics(eval_pred):
    logits, labels = eval_pred
    preds = np.argmax(logits, axis=-1)
    accuracy = accuracy_score(labels, preds)
    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')
    return {
        "accuracy": accuracy,
        "precision": precision,
        "recall": recall,
        "f1": f1
    }

"""Tokenizerの取得"""

from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

"""学習用データの読込"""

from google.colab import drive
from sklearn.model_selection import train_test_split
from datasets import Dataset, DatasetDict
import pandas as pd

drive.mount('/mount')
data = pd.read_json('/mount/MyDrive/corpus.json')

train, valid = train_test_split(data, test_size=0.25)

ds_train = Dataset.from_pandas(train)
ds_valid = Dataset.from_pandas(valid)

dataset = DatasetDict({
    "train": ds_train,
    "validation": ds_valid,
})

"""文章をトークンに変換"""

import torch

# 変換関数
def preprocess_function(data):
    texts = [q.strip() for q in data["text"]]
    inputs = tokenizer(
        texts,
        # max_length=450,
        # truncation=True,
        # padding=True,
        padding='max_length',
        truncation=True,
        max_length=512,
    )

    # inputs['labels'] = torch.tensor(data['label'])
    inputs['labels'] = data['label']

    return inputs


# 変換
tokenized_data = dataset.map(preprocess_function, batched=True)

"""分類用のモデルを取得する"""

from transformers import AutoModelForSequenceClassification

num_labels = 2 # 分類する種類の数

# デバイス判定
device = "cuda:0" if torch.cuda.is_available() else "cpu"

model = AutoModelForSequenceClassification.from_pretrained("bert-base-uncased", num_labels=num_labels).to(device)

"""パラメータを設定する"""

from transformers import TrainingArguments

training_args = TrainingArguments(
    output_dir="/mount/MyDrive/bert1",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    save_total_limit=1,
    # learning_rate=2e-5,
    learning_rate=5e-5,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    # num_train_epochs=200,
    num_train_epochs=3,
    weight_decay=0.01,
    load_best_model_at_end=True,
)

from transformers import default_data_collator
data_collator = default_data_collator

"""**学習を実行**"""

from sklearn.model_selection import train_test_split
from transformers import Trainer, EarlyStoppingCallback

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_data["train"],
    eval_dataset=tokenized_data["validation"],
    data_collator=data_collator,
    tokenizer=tokenizer,
    callbacks=[EarlyStoppingCallback(early_stopping_patience=30)],
    compute_metrics=compute_metrics
)

trainer.train()

"""評価結果の確認"""

eval_result = trainer.evaluate()
print(eval_result)

"""学習後の動作確認"""

from torch import nn

def predict(text):
    inputs = tokenizer(text, add_special_tokens=True, return_tensors="pt").to(device)
    outputs = model(**inputs)
    ps = nn.Softmax(1)(outputs.logits)

    max_p = torch.max(ps)
    result = torch.argmax(ps).item() if max_p > 0.8 else -1
    return result

result = predict("I ain't got no time for that.")               # Native(label:1) example
# result = predict("I am not going to do anything about it.")     # Non-Native(label:0) example

print(result)
